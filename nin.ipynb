{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nin.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xingchenzhao/study_deep_learning/blob/master/nin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPy-2luChIho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install d2lzh  # installing d2l\n",
        "!pip install -U --pre mxnet-cu101mkl  # updating mxnet to at least v1.6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUbgrp7ChQYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import d2lzh as d2l\n",
        "from mxnet import gluon, init, nd\n",
        "from mxnet.gluon import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEeNuipfny_9",
        "colab_type": "text"
      },
      "source": [
        "**Network in Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xymRk4ONn89s",
        "colab_type": "text"
      },
      "source": [
        "Instead of using dense layer, we use 1*1 conv layer for each nin block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb_guctAhSQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nin_block(num_channels, kernel_size, strides, padding):\n",
        "  blk = nn.Sequential()\n",
        "  blk.add(nn.Conv2D(num_channels, kernel_size,\n",
        "                    strides, padding, activation='relu'),\n",
        "          nn.Conv2D(num_channels, kernel_size=1, activation='relu'),\n",
        "          nn.Conv2D(num_channels, kernel_size=1, activation='relu'))\n",
        "  return blk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoftOqpdiTIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = nn.Sequential()\n",
        "net.add(nin_block(96,kernel_size=11, strides=4, padding=0),\n",
        "        nn.MaxPool2D(pool_size=3, strides=2),\n",
        "        nin_block(256,kernel_size=5, strides=1, padding=2),\n",
        "        nn.MaxPool2D(pool_size=3, strides=2),\n",
        "        nin_block(384,kernel_size=3, strides=1, padding=1),\n",
        "        nn.MaxPool2D(pool_size=3, strides=2), nn.Dropout(0.5),\n",
        "        nin_block(10,kernel_size=3, strides=1,padding=1),\n",
        "        nn.GlobalAvgPool2D(),\n",
        "        nn.Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klMgPdFTjVPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = nd.random.uniform(shape=(1,1,224,224))\n",
        "net.initialize()\n",
        "for layer in net:\n",
        "  X = layer(X)\n",
        "  print(layer.name, 'output shape:\\t', X.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhY4lqnajkhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fe4ee749-80fa-4e31-d955-b9114c86f693"
      },
      "source": [
        "lr, num_epochs, batch_size, ctx = 0.1, 10, 128, d2l.try_gpu()\n",
        "net.initialize(force_reinit=True, ctx=ctx, init=init.Xavier())\n",
        "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate':lr})\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
        "d2l.train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx, \n",
        "              num_epochs)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on gpu(0)\n",
            "epoch 1, loss 2.0916, train acc 0.211, test acc 0.416, time 70.7 sec\n",
            "epoch 2, loss 1.5695, train acc 0.398, test acc 0.431, time 70.7 sec\n",
            "epoch 3, loss 1.3895, train acc 0.511, test acc 0.584, time 70.6 sec\n",
            "epoch 4, loss 1.1871, train acc 0.583, test acc 0.613, time 70.8 sec\n",
            "epoch 5, loss 1.0356, train acc 0.622, test acc 0.629, time 70.9 sec\n",
            "epoch 6, loss 1.1066, train acc 0.600, test acc 0.628, time 71.0 sec\n",
            "epoch 7, loss 0.9857, train acc 0.637, test acc 0.641, time 71.1 sec\n",
            "epoch 8, loss 0.9572, train acc 0.647, test acc 0.648, time 71.0 sec\n",
            "epoch 9, loss 0.9410, train acc 0.652, test acc 0.651, time 71.1 sec\n",
            "epoch 10, loss 0.9255, train acc 0.658, test acc 0.657, time 71.1 sec\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}